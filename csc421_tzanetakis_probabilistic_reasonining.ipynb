{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAPTER 13 - Probabilistic Reasoning \n",
    "\n",
    "### George Tzanetakis, University of Victoria \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKPLAN \n",
    "\n",
    "The section number is based on the 4th edition of the AIMA textbook and is the suggested\n",
    "reading for this week. Each list entry provides just the additional sections. For example the Expected reading include the sections listed under Basic as well as the sections listed under Expected. Some additional readings are suggested for Advanced. \n",
    "\n",
    "1. Basic: Sections **13.1**, **13.2 (not 13.2.1, 13.2.2, 13.2.3, 13.2.4)**, **13.3 (just exact inference)**, **13.4 (just direct sampling)**, and **Summary**\n",
    "2. Expected: Same as Basic + in 13.3 variable elimination) + in 1.34 (+ rejection sampling) \n",
    "3. Advanced: All the chapter including bibligraphical and historical notes \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History \n",
    "\n",
    "Pierre Laplace (1819): \"Probability theory is nothing but common sense reduced to calculation\" \n",
    "\n",
    "James Maxwell (1850): \"The true logic for this world is the calculus of probabilities, which takes account of the magnitude of the probability which is, or ought to be, in a reasonable man's mind.\" \n",
    "\n",
    "Early expert system of 1970s focused on logic and ignored uncertainty. Next generation medical diagnostic systems used probabilistic techniques but run into issues of scalability when using full joint distributions. Probabilistic approaches fell out of fashion from roughly 1975 to 1988. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference using full joint distribution\n",
    "\n",
    "\n",
    "Let's consider another example where the full joint distribution $2 x 2 x 2$ is given. \n",
    "\n",
    "\n",
    "\n",
    "|---| toothache and catch    | toothache and not catch | not toothache and catch | not toothache and not catch | \n",
    "|---|-------   | ----------| ------| ----------|\n",
    "|cavity | 0.108 | 0.012 | 0.072 | 0.008 | \n",
    "| not cavity | 0.016 | 0.064 | 0.144 | 0.576 | \n",
    "\n",
    "\n",
    "Direct way to evalute the probability of any proposition: \n",
    "* Identify the possible worlds in which a proposition is true and add up their probabilities \n",
    "* $P(cavity \\lor toothache) = 0.108 + 0.012 + 0.072 + 0.008 + 0.016+ 0.064 = 0.28$ \n",
    "* **Marginal probability** of cavity: \n",
    "* $P(cavity) = 0.108 + 0.012 + 0.072 + 0.008 = 0.2$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The big picture \n",
    "\n",
    "We represent problems as sets variables with discrete and finite domains. The full joint probability distribution specifies probabilities for every possible assignment of all the variables to values from their corresponding domain. In a typical scenario we are given the values of some variables (called evidence) and are interested in the probability distribution of some variables (called query) given the evidence. The remaining variables are called the hidden variables. \n",
    "\n",
    "\n",
    "Without going into details, we can solve any inference problem by summation and products using the full joint probability distribution. \n",
    "\n",
    "The problem with this approach is that specifying the joint probability distribution becomes \n",
    "very difficult as the number of variables increases. For example if we have 10 binary random variables we would need to provide $2^{10}=1024$ probability values. Specifying probabilities \n",
    "\n",
    "We can take advantage of independence and conditional independence relationships among the random variables specifying our problem to greatly reduce the number of probabilities that need to be specified in order to define the full joint probability distribution. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Bayesian Networks  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Bayesian Network is as specific case of a Probabilistic Graphical Model. \n",
    "\n",
    "\n",
    "\n",
    "Specifying a Bayesian Network \n",
    "\n",
    "1. Each node corresponds to a random variable, which may be discrete or continuous \n",
    "2. Directed links connect pairs of nodes. If there is an arrow from node X to node Y, X is called the **parent** of Y. The graph has no directed cycles and hence is a directed acyclic graph, or DAG. \n",
    "3. Each node $X_{i}$ has associated probability information $\\theta(X_i|Parents(X_i))$ that quantifies the effect oif the parents on the node using a finite number of parameters. \n",
    "\n",
    "(Causes should be parents of effects - this is typically something that a domain expert can easily do) \n",
    "\n",
    "The joint distribution can be calculated from all the variables defined by the topology and the local probability information. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Network Example \n",
    "\n",
    "\n",
    "Let's look at a particular well-known example of a Bayesian Network, originally proposed by Judea Pearl, a well-known computer scientist. \n",
    "\n",
    "<img src=\"images/judea_pearl_bayes_net.png\" width=\"75%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantics of Bayesian Networks \n",
    "\n",
    "\n",
    "An entry in the joint probability distribution is: \n",
    "* $P(X_{1} = x_{1} \\wedge ... \\wedge X_{n} = x_{n})$ or $P(x_1,x_2,..,x_{n})$\n",
    "\n",
    "The Bayesian Network can be used to calculate each entry \"on demand\" as follows: \n",
    "\n",
    "* $P(x_1,x_2,..,x_{n}) = \\prod_{i=1}^{n} \\theta(x_{i} | parents(X_{i}))$\n",
    "\n",
    "Let's illustrate this with an example based on the network above: \n",
    "\n",
    "* $P(j,m,a,\\lnot b, \\lnot e) = P(John = True \\land Mary = True \\land \\dots ) = P(j|a) P(m|a) P(a| \\lnot b \\lnot e) P(\\lnot b) P(\\lnot e) $\n",
    "* $= 0.90 \\times 0.70 \\times 0.001 \\times 0.999 \\times 0.998 = 0.000628 $\n",
    "* $P(\\lnot j, m, \\lnot a, b, e) = 0.95 \\times 0.01 \\times .05 \\times .001 \\times .002$\n",
    "\n",
    "Note the above uses short-hand notation. If we wanted to be more precise we should have written the expression as follows: \n",
    "$P(JohnCalls = True \\wedge MaryCalls = True ... )$\n",
    "\n",
    "\n",
    "As the number of variables increases specifying the full joint probability distribution requires many more numbers than specifying a Bayesian Network. If we have $n$ boolen variables and each variables has $k$ parents \n",
    "the complete network can be specified by $2^{k} \\cdot n$ numbers. \n",
    "\n",
    "For example suppose that you have 30 variables and each one has 5 parents. The Baysian Network requires $32 * 30=960$ but the full distribution requires over a billion. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Bayesian Network \n",
    "\n",
    "\n",
    "Ideally parents of a node contain all the nodes that directly influence that node. \n",
    "It is possible for the same joint probability distribution to be represented by networks \n",
    "created by adding nodes in different orders. These networks can be clunky and hard to understand. \n",
    "\n",
    "\n",
    "Intuitively:\n",
    "* Start from root causes and expand effects –(follow causality) \n",
    "* For details: Read textbook\n",
    "\n",
    "<img src=\"images/different_orders_bayes_net.png\" width=\"75%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Inference by Enumeration\n",
    "\n",
    "\n",
    "The basic task of probabilistic inference system is to compute the posterior probability distribution for a set of **query variables**, given some observed **event** which is an assignment of values to a set of **evidence variables**. For presentation we will look into single query variables. The remaining variables are called **hidden**. \n",
    "\n",
    "**Note it is possible to express multiple query variables in terms of single variable queries ** \n",
    "* Simple queries $P(NoGas | Gauge = empty, Lights = on, Starts =false)$\n",
    "* Conjuctive queries $P(Xi , Xj | E = e) = P(Xi| E = e) P(Xj| Xi,, E =e)$ \n",
    "\n",
    "For example in the burglary network: \n",
    "\n",
    "* $P(Burglary | JohnCalls = true, MaryCalls=true) = 0.716$\n",
    "\n",
    "### Inference by enumeration \n",
    "\n",
    "$P(X|e) = \\alpha P(X,e) = \\alpha \\sum_{y} P(X,e,y)$\n",
    "\n",
    "So basically any query can be answered using a Bayes net by computing sum of products of conditional probabilities from the network. \n",
    "\n",
    "\n",
    "For example: \n",
    "\n",
    "* $P(b | j,m) = \\alpha \\sum_{e} \\sum_{a} P(b) P(e) P(a|b,e) P(j|a) P(m|a) = \\alpha P(b) \\sum_e P(e) \\sum_a P(a|b,e) P(j|a) P(m|a)$\n",
    "\n",
    "* Shortname for $P(B=True | J=True and M = True)$\n",
    "\n",
    "Note the use of $\\alpha$ for normalization: \n",
    "\n",
    "* $ P(B|j,m) = \\alpha <0.00059224, 0.0014919> \\approx <0.284, 0.716> $\n",
    "\n",
    "The chance of burglary if both mary and john call. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bayes_inference_enumeration.png\" width=\"75%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable elimination \n",
    "\n",
    "Notice in the figure above showing the structure of the expression tree for direct enumeration there are several repeated multiplications. More efficient direct enumeration algorithms can be devised by doing calculations once and saving the results for later use. \n",
    "This is a form of **dynamic programming**. The **variable elimination** algorithm is a simple algorithm that works by evaluating expressions in bottom up order and storing intermediate results as factors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Blanket \n",
    "\n",
    "A node is conditionally independent of all other nodes in the network, given its parents, children, and children's parents - that is given its **Markov Blanket**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A bigger example of a Bayes net \n",
    "\n",
    "<img src=\"images/car_diagnostics_bayes.png\" width=\"75%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional topics \n",
    "\n",
    "\n",
    "* Markov blankets, ancestral graph, moral graph \n",
    "* Efficient representation of conditional distributions \n",
    "* Bayesian networks with continuous variables \n",
    "* Car insurance case study \n",
    "* Variable elimination algorithm \n",
    "* Complexity of exact inference \n",
    "* Clustering algorithms \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximate Inference "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that instead of calculating the exact probabilities of events we are interested in we can simulate stochastically the generation of samples using the network and simply count. Approximate inference can be much more efficient than exact inference for large networks. \n",
    "\n",
    "\n",
    "* Draw N samples from a sampling distribution \n",
    "*Compute an approximate posterior P\n",
    "* Show this converges to true prob. \n",
    "\n",
    "Examples of approximate inference: \n",
    "\n",
    "* Sampling from an empty network \n",
    "* Rejection sampling: reject samples disagreeing with evidence \n",
    "* Likelihood weighting: use evidence to weight samples \n",
    "* Markov Chain Monte Carlo (MCMC): sample from a stochastic process whose stationary distribution approximates the distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling from a network with no evidence "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate events from a network with no evidence associated with it \n",
    "\n",
    "Idea:  \n",
    "* sample each variable in turn, in topological order, conditioning variables appropriately \n",
    "* Count actual samples generate \n",
    "* Frequency converges the more samples we generate \n",
    "* Consistent estimate = converges to true probability in the largesample limit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/approximate_inference1.png\" width=\"75%\"/>\n",
    "<img src=\"images/approximate_inference2.png\" width=\"75%\"/>\n",
    "<img src=\"images/approximate_inference3.png\" width=\"75%\"/>\n",
    "<img src=\"images/approximate_inference4.png\" width=\"75%\"/>\n",
    "<img src=\"images/approximate_inference5.png\" width=\"75%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rejection Sampling \n",
    "\n",
    "\n",
    "* P'(X/e) estimated from samples agreeing with e \n",
    "* Use direct sampling to generate N samples, then select the ones that agree with evidence \n",
    "* For example to estimate $P(Rain | Sprinkler = true)$ generate $100$ samples. \n",
    "* Let's say we have 27 samples that have Sprinkler=true and out of those 8 have $Rain=True$ \n",
    "and $19$ have $Rain = False$ \n",
    "* $P'(Rain | Sprinkler = True) = Norm(<8,19>) = <0.296, 0.704>$\n",
    "* Rejection sampling returns consistent posterior estimates \n",
    "* Problem: –Hopelessly expensive if P(e) is small \n",
    "    * Why ? \n",
    "* P(e) drops exponentially with number of evidence variables \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Weighting\n",
    "\n",
    "\n",
    "* Idea: fix evidence variables, sample only nonevidence variables and weight each sample with the likelihood it affords the evidence \n",
    "\n",
    "* Produces consistent estimates (details in book)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Simulation\n",
    "\n",
    "MCMC algorithms work quite differently from rejection sampling and likelihood weighting. Instead of generating each sample from scratch, MCMC algorithms generate each sample by making a random change to a the preceding sample. It is therefore helpful to think of an MCMC algorithms as being in a particular **current state** specifying a value for each variable and generating a **next state** by making random changes to the current state. \n",
    "There are several MCMC algorithms - a simple example is **Gibbs** sampling. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
