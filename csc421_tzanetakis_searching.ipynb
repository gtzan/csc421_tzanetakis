{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CSC 421 - Searching \n",
    "\n",
    "### Instructor: George Tzanetakis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving Problems by Searching \n",
    "\n",
    "\n",
    "**Search**: Find sequence of actions that form a path to a goal state. \n",
    "\n",
    "Simplest possible environemnts: episodic, single agent, fully observable, deterministic, static, discrete, and known. \n",
    "\n",
    "\n",
    "During this unit we will cover the following topics: \n",
    "\n",
    "1. Problem-solving agents \n",
    "2. Example problems \n",
    "3. Search algorithms \n",
    "4. Uninformed search strategies \n",
    "5. Informed (Heuristic) search strategies \n",
    "6. Heuristic functions \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WORKPLAN \n",
    "\n",
    "The section number is based on the 4th edition of the AIMA textbook and is the suggested\n",
    "reading for this week. Each list entry provides just the additional sections. For example the Expected reading include the sections listed under Basic as well as the sections listed under Expected. Some additional readings are suggested for Advanced. \n",
    "\n",
    "1. Basic: Sections **3.1**, **3.2**, **3.3**, **3.4.1**, **3.4.2**, **3.4.3**, **3.5.2**, **3.6.1**, **3.6.2** and **Summary**\n",
    "2. Expected: **3.4.4**, **3.4.5**, **3.4.6**\n",
    "3. Advanced: All the chapter including bibligraphical and historical notes \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem-Solving Agents\n",
    "\n",
    "\n",
    "Map of Romania example  \n",
    "\n",
    "1. Goal formulation: reach Bucharest \n",
    "2. Problem formulation: description of states and actions - abstract model of problem \n",
    "3. Search: Simulate sequences of actions in its model until solution reaching goal is found \n",
    "4. Execution: Execute the actions in the solution - one at a time \n",
    "\n",
    "\n",
    "<img src=\"images/romania_map.png\" width=\"80%\"/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search problems and solutions \n",
    "\n",
    "\n",
    "* State space: all possible states (all cities of the map) \n",
    "* Initial state: (start city) \n",
    "* Goal states (end city or cities) \n",
    "* Actions: **ACTIONS(S)** returns finite set of actions that can be executed in **s** \n",
    "* Transition model: **RESULTS(s,a)->s'** returns the state **s'** that results from doing action **a** in state **s** \n",
    "* Action cost function: **ACTION-COST(s,a,s')** returns a numeric cost of applying action **a** when in state **s** to reach state **s'** \n",
    "\n",
    "\n",
    "A sequence of actions forms a **path**. A **solution** is a path from the initial state to a goal state. \n",
    "Actions costs are additive. **Optimal solution** has the lowest path cost among all solutions. \n",
    "\n",
    "The state space can be represented a **graph** in which the vertices are the states and the directed edges between them are actions. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of search problems:\n",
    "\n",
    "* Board games\n",
    "* Scheduling\n",
    "* Theorem proving\n",
    "* Robot Navigation\n",
    "* Combat NPC in game\n",
    "* The workhorse of old classic AI\n",
    "\n",
    "\n",
    "Works well for **“toy words”** \n",
    "* SAINT (James Stagle (blind computer scientist), 1963) closed-form calculus integration problems \n",
    "* ANALOGY (Tom Evans, 1968) geometry analogy problems that appear in IQ tests \n",
    "* Blocks world (vision, constraint-propagation, learning, natural language understanding) including robotics version\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/block_world.png\" width=\"60%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXAMPLE DIALOG\n",
    "\n",
    "* Person: PICK UP A BIG RED BLOCK.\n",
    "* Computer: OK. (does it)\n",
    "* Person: GRASP THE PYRAMID.\n",
    "* Computer: I DON'T UNDERSTAND WHICH PYRAMID YOU MEAN.\n",
    "* Person: FIND A BLOCK WHICH IS TALLER THAN THE ONE YOU ARE HOLDING AND PUT IT INTO THE BOX.\n",
    "* Computer: BY \"IT\", I ASSUME YOU MEAN THE BLOCK WHICH IS TALLER THAN THE ONE I AM HOLDING.\n",
    "* Computer: OK. (does it)\n",
    "* Person: WHAT DOES THE BOX CONTAIN?\n",
    "* Computer: THE BLUE PYRAMID AND THE BLUE BLOCK.\n",
    "* Person: WHAT IS THE PYRAMID SUPPORTED BY?\n",
    "* Computer: THE BOX.\n",
    "* Person: HOW MANY BLOCKS ARE NOT IN THE BOX?\n",
    "* Computer: FOUR OF THEM.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example problems\n",
    "<img src=\"images/vacuum_world_state_space.png\" width=\"100%\"/>\n",
    "\n",
    "### Vacuum world \n",
    "\n",
    "* **States**: 8 possible world states (two locations, agent position, dirt locations). More generally $n \\times 2^n$ states when there are $n$ locations \n",
    "* **Initial state**: Any state\n",
    "* **Actions** Each state has just three actions: *Left*, *Right*, *Suck*\n",
    "* **Transition Model** each actions has the usual effect except when the agent can't move on the left or right edge or there is no dirt in which case the state remains the same\n",
    "* **Goal test**: Checks that all the squares are clean\n",
    "* **Path cost** Each step costs 1, so the path cost is the number of steps in the path\n",
    "\n",
    "### Eight queens \n",
    "<img src=\"images/eight_queens_puzzle.png\" width=\"50%\"/>\n",
    "\n",
    "\n",
    "### Knuth Infinite State Space \n",
    "\n",
    "Knuth conjuectured that starting with the number 4, a sequence of repeated applications of factorial, square root, and floor operations will reach any desired positive integer. For example, one can reach 5 from 4 as follows: \n",
    "\n",
    "$$\n",
    "\\left \\lfloor \\sqrt{\\sqrt{\\sqrt{\\sqrt{\\sqrt{(4!)!}}}}} \\right \\rfloor = 5 \n",
    "$$\n",
    "\n",
    "The problem definition is: \n",
    "\n",
    "* **States**: Positive numbers\n",
    "* **Initial state**: 4\n",
    "* **Actions**: Apply factorial, square root, or floor operation (factorial for integers only)\n",
    "* **Transition model** Use the mathematical definitions of the operations\n",
    "* **Goal test**: The state is the desired positive integer\n",
    "  \n",
    "Really large numbers can be constructed in the process of reaching a given target and the state space is infinite. For example according to the textbook the number $620,448,401,733,239,.439,360,000$ is generated in the expression for reaching $5$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### INTERACTIVE \n",
    "\n",
    "\n",
    "Let's formulate as search problems (be precise - common midterm/final question) \n",
    "\n",
    "1. 2D Maze navigation - discuss different action/state formulations \n",
    "2. Sliding-tile puzzle \n",
    "3. Route-finding\n",
    "4. Single chess piece movement on chess board using only valid moves \n",
    "\n",
    "What is the state space, initial state, goal state, actions, transition model, action-cost ? \n",
    "\n",
    "**Important note:** for many problems more than one search problem formulation is possible \n",
    "\n",
    "\n",
    "Others: VLSI layout, robot navigation, automatic assembly sequencing \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPHS ARE YOUR FRIEND \n",
    "\n",
    "The main challenge when formulating an actual problem as a search problem is how to represent the problem as \n",
    "a graph. Turn AI problems into graphs and you are done. \n",
    "\n",
    "<img src=\"images/plan_graph.png\" width=\"60%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A search algorithm takes as input a search problem and returns a solution or failure if none can be found. \n",
    "\n",
    "**Search tree** algorithms superimpose a search tree over the state-space graph, forming various paths from the initial state, trying to find a path that reaches a goal state. \n",
    "\n",
    "**IMPORTANT** distinction between state space and search tree. The state space describes the potentially infinite set of states in the world, and the actions that allow transitions from one state to the other. The search tree describes paths between these states, reaching toward the goal. The search tree can have multiple nodes corresponding to any given state but each node in the tree has a unique path back to the root. \n",
    "\n",
    "\n",
    "Each node is **expanded** by considering the available **ACTIONS** and using the **RESULT** function to see where those lead to and then **generating** a new node (called a **child node**) for each of the resulting states. \n",
    "Each child has a parent node. \n",
    "\n",
    "Next, we must choose which of the child notes to consider next. Let's say we expand a particular child. The set of yet to be expanded nodes is called the **frontier**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/romania_map.png\" width=\"80%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node representation \n",
    "\n",
    "* node.STATE \n",
    "* node.PARENT \n",
    "* node.ACTION (applied to parent to generate node)\n",
    "* node.PATH_COST (total cost of the path from the initial state to this node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frontier representation\n",
    "\n",
    "\n",
    "The set of all leaf nodes available for expansion at any given point is called the **frontier**. The **search strategy** defines which state to expand next. \n",
    "\n",
    "The data structure used to store nodes during the formation of the search tree is a **queue**.\n",
    "\n",
    "Queue \n",
    "\n",
    "* IS-EMPTY(frontier)\n",
    "* POP(frontier): remove top node from the frontier and returns it\n",
    "* TOP(frontier): returns (but does not remove) the top node from the frontier \n",
    "* ADD(node, frontier): inserts node into its proper place in the queue \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "* Priority queue -> best first search\n",
    "* FIFO queue     -> breadth-first search \n",
    "* LIFO queue     -> depth-first search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/uninformed_search1.png\" width=\"60%\"/>\n",
    "<img src=\"images/uninformed_search2.png\" width=\"60%\"/>\n",
    "<img src=\"images/uninformed_search3.png\" width=\"60%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** : Redundant paths: cycles/redundant paths arise naturally in many problems \n",
    "For example consider a 10x10 grid with the ability to move to any of the adjacent 8 squares. \n",
    "Number of paths of length 9 is almost 8^9 (> 100 million). \n",
    "\n",
    "* **GRAPH_SEARCH**: checks for redundant paths \n",
    "* **TREE_SEARCH**: does not check for redundant paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **state** is a representation of a physical\n",
    "configuration\n",
    "\n",
    "A **node** is a data structure constituting part of a\n",
    "search tree including (parent, children, depth, cost\n",
    "g(x))\n",
    "\n",
    "States do not have parents, children or costs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/state_vs_node.png\" width=\"80%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring problem-solving performance \n",
    "\n",
    "A search strategy is defined by picking the order of node expansion\n",
    "\n",
    "Strategies are evaluated along the following dimensions:\n",
    "* **completeness**: does it always find a solution if one exists?\n",
    "* **time complexity**: number of nodes generated\n",
    "* **space complexity**: maximum number of nodes in memory\n",
    "* **optimality**: does it always find a least-cost solution?\n",
    "\n",
    "\n",
    "Time and space complexity:\n",
    "\n",
    "* **b**: maximum branching factor of the search tree\n",
    "* **d**: depth of the least-cost solution\n",
    "* **m**: maximum depth of the state space (can be infinite) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/uninformed_search_comparison.png\" width=\"80%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRACTICE questions\n",
    "\n",
    "1. Create a simple binary tree and label the nodes randomly - show how the frontier or the search tree evolves after every iteration of any of the uninformed search algorihthms \n",
    "2. Create a tree (not necessarily binary) and label the nodes randomly - show how the frontier or the search tree evolves after every iteration of any of the uninformed search algorihthms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFORMED SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main Idea**: use an evaluation function for each node – estimate of **“desirability”**   \n",
    "    \n",
    "Expand most desirable unexpanded node\n",
    "\n",
    "\n",
    "Implementation:\n",
    "\n",
    "Frontier is a queue sorted in decreasing order of desirability\n",
    "\n",
    "Examples: \n",
    "\n",
    "1. **Greedy search**: f(n) = h(n): select the closet node to the goal according to the heuristic \n",
    "2. **A*-search: f(n)** = g(n) + h(n): select the closest node to the goal according to the heuristic \n",
    "taking into account the sum of the path cost from the start to the node plus the closest node to the goal according to the heuristic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/romania_map_with_heuristic.png\" width=\"80%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRACTICE ### \n",
    "\n",
    "1. Carefully understand the examples of greedy and A* search described in the book (Figure 3.17 and Figure 3.18)\n",
    "2. Select a different pair of start and goal using the Romania map and work out how greedy and A* search work \n",
    "3. Make your own map  and work out how greedy and A* search would work for this example. \n",
    "4. Model a different problem as a search problem using a graph, come up with a reasonable heuristic. Then \n",
    "create a specific example and work out how greey and A* search would work for this example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heuristics \n",
    "\n",
    "* **Admissible heuristic**: is one that never overestimates the cost to reach a goal \n",
    "* **Consistent heuristic**: h(n) <= c(n,a,n') + h(n'), a form of triangle inequality \n",
    "\n",
    "\n",
    "For real world problems coming up with a good heuristic can reduce significanlty search times but is not trivial. \n",
    "A good approach is to think about relaxed versions of the problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8-puzzle, heuristic functions, and relaxed problems \n",
    "\n",
    "\n",
    "Consider the tiling 8-puzzle. The object of the puzzle is to slide the tiles horizontally or vertically into the empty space until the configuration matches the goal configuration. There are 9!/2 = 181400 reachable states. For k-puzzle problems there are two commonly used heuristics: \n",
    "\n",
    "1. **h1** number of misplaced tiles - admissible because any tile that is out of place will require at least one move \n",
    "2. **h2**: sum of the distances of the titles from their goal positions - city-block (Manhattan) distance \n",
    "\n",
    "\n",
    "<img src=\"images/eight-puzzle.png\" width=\"60%\"/>\n",
    "\n",
    "For this example **h1** is 8 and **h2** is 3+1+2+2+2+3+3+2=18 and the true solution cost is 26. Both do not overestimate the true solution cost. \n",
    "\n",
    "\n",
    "Figure 3.26 in the book shows a comparison of the search costs using BFS, A* with h1, and A* with h2. Data are averaged over 100 puzzles for each solution length d from 6 to 28 \n",
    "\n",
    "| d  | BFS    | A*(h1) | A*(h2) |\n",
    "|----|--------|--------|--------|\n",
    "| 6  | 128    | 24     | 19     |\n",
    "| 8  | 368    | 48     | 31     |\n",
    "| 10 | 1033   | 116    | 48     |\n",
    "| 12 | 2672   | 279    | 84     |\n",
    "| 14 | 6783   | 678    | 174    |\n",
    "| 16 | 17270  | 1683   | 364    |\n",
    "| 18 | 41558  | 4102   | 751    |\n",
    "| 20 | 91493  | 9905   | 1318   |\n",
    "| 22 | 175921 | 22955  | 2548   |\n",
    "| 24 | 290082 | 53039  | 5733   |\n",
    "| 26 | 395355 | 110372 | 10080  |\n",
    "| 28 | 463234 | 202565 | 22055  |\n",
    "\n",
    "\n",
    "\n",
    "**h1** and **h2** can also be viewed as accurate path lengths for simplified versions of the puzzle. Move square anywhere corresponds to **h1** and move one square in any direction even onto occupied space corresponds to **h2**. \n",
    "\n",
    "\n",
    "Removal of restrictions creates added edges to the state-space graph that can result in \"short-cuts\" providing \n",
    "\"better\" solution - the optimal solution to the original problem will still be a solution for the relaxed problem. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A* in modern computer games \n",
    "\n",
    "\n",
    "* Simplifying search space without compromising \n",
    "    * Hierarchical path finding \n",
    "    * Waypoints \n",
    "    * Navigation mesh \n",
    "* Memory issues \n",
    "    * Node bank \n",
    "    * IDA*\n",
    "* Game examples \n",
    "    * Age of empires \n",
    "    * Civilization \n",
    "    * World of Warcraft \n",
    "    \n",
    "    \n",
    "<img src=\"images/waypoint.png\" width=\"60%\"/>\n",
    "\n",
    "    \n",
    "<img src=\"images/age_of_empires.png\" width=\"60%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "~~~\n",
    "function BEST-FIRST-SEARCH(problem, f ) returns a solution node or failure\n",
    "    node ← NODE(STATE=problem.INITIAL)\n",
    "    frontier ← a priority queue ordered by f , with node as an element\n",
    "    reached ←a lookup table, with one entry with key problem.INITIAL and value node\n",
    "    while not IS-EMPTY(frontier ) do\n",
    "        node ← POP(frontier )\n",
    "        if problem.IS-GOAL(node.STATE) then return node\n",
    "        for each child in EXPAND(problem, node) do\n",
    "            s ← child.STATE\n",
    "            if s is not in reached or child.PATH-COST < reached[s].PATH-COST then\n",
    "                reached[s] ←child\n",
    "    add child to frontier\n",
    "return failure\n",
    "\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
