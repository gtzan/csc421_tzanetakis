{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 18 - Learning \n",
    "\n",
    "### George Tzanetakis, University of Victoria \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## WORKPLAN \n",
    "\n",
    "The section number is based on the 3th edition of the AIMA textbook and is the suggested\n",
    "reading for this week. Each list entry provides just the additional sections. For example the Expected reading include the sections listed under Basic as well as the sections listed under Expected. Some additional readings are suggested for Advanced.\n",
    "In the 4th edition of the AIMA textbook this notebook corresponds to Chapter 19. \n",
    "\n",
    "1. Basic: Sections **18.1**, **18.2**, and **Summary**\n",
    "2. Expected: Same as Basic plus **18.3**, **18.6**, **18.7**\n",
    "3. Advanced: All the chapter including bibligraphical and historical notes \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forms of learning  \n",
    "\n",
    "An agent is **learning** if it improves its performance on future tasks after making observations about the world. \n",
    "In this chapter, we focus on a simple type of learning problem which is given a collection of input-output pairs, learn \n",
    "a function that predicts the output for new inputs. Even though at first glance this seems like a simple learning problem \n",
    "it has a large number of applications. \n",
    "\n",
    "## Feedback to learn from \n",
    "\n",
    "There are *types of feedback* that determine the three main types of learning: \n",
    "\n",
    "* **Unsupervised learning:** the agent learns patterns in the input without any explicit feedback. The most common example of unsuprvised learning is **clustering**\n",
    "* **Reinforcement learning:** the agent learns from a series of reinforcements (rewards and punishments).\n",
    "* **Supervised learning:** the agent observes some example input/output pairs and learns a function that maps the input to output. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.91937372 3.18085914 2.96061671 3.14703314 3.62033756 3.01562753\n",
      " 3.09941826 3.29013467 3.24339263 3.0781077 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "mu = 3.0 \n",
    "sigma = 0.2 \n",
    "s = np.random.normal(mu, sigma, 10)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "samples = np.random.normal(mu, sigma, 10000)\n",
    "print(len(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Simple Naive Bayes binary classification example\n",
    "\n",
    "In this notebook I will show a very simple example of this idea. Hopefully this will give you some general intuition about this approach. Then you can review the specific book examples that are more complicated (learning Gaussian mixtures, Bayesian networks with hidden variables, and learning hmm parameters). We will end by showing the general mathematical notation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a simple binary classification problem with one continous attribute. For example this could be classifying whether some one is a professional basketball player or not based on their height. We can generate some synthetic data for this problem by simply sampling two Gaussian distribution. Let's say that professional basketball players have an average height of 190cm and the average height of other people is 175cm. For simiplicity we will consider they both have a standard deviation of 10cm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generate twenty samples of each class \n",
    "bball_samples = np.random.normal(190, 10, 20)\n",
    "other_samples = np.random.normal(175, 10, 20)\n",
    "print(bball_samples)\n",
    "print(other_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 1000 samples of each class and plot histogram \n",
    "\n",
    "bball_mean_height = 190 \n",
    "other_mean_height = 175 \n",
    "bball_samples = np.random.normal(bball_mean_height, 10, 100)\n",
    "other_samples = np.random.normal(other_mean_height, 10, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "bins = np.linspace(150, 220, 100)\n",
    "pyplot.hist(bball_samples, bins, alpha=0.5, label='x')\n",
    "pyplot.hist(other_samples, bins, alpha=0.5, label='y')\n",
    "pyplot.legend(loc='upper right')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can clearly see in the histogram the height-distribution and overlap. You can also see that there is an equal number of instances for each class and that the standard deviation is the same.\n",
    "\n",
    "Now suppose that you are just given the nba_samples and other_samples and told that these are labeled samples for training a Naive Bayes classifier. You also know that they both have a standard deviation of 10cm so we will keep that. In this case the only parameter we are trying to estimate is the mean of each class. So ùúÉ=(ùúáùëõùëèùëé,ùúáùëúùë°‚Ñéùëíùëü).\n",
    "\n",
    "Given this data the maximum-likelihood estimate for the means is easily obtained by taking the statistical mean of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_bball = np.mean(bball_samples)\n",
    "mu_other = np.mean(other_samples)\n",
    "print(mu_bball, mu_other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have \"learned\" a model we can use it to predict. Suppose you are given a test height - lets say 183cm. You can calcuate the $P(183/nba)$ and $P(183/other)$ by using the corresponding probability density functions characterized by $\\mu_{nba}$ and $\\sigma = 10$ and $\\mu_{other}$ and $\\sigma = 10$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "test_height = 200\n",
    "\n",
    "p_bball = norm(mu_bball, 10).pdf(test_height)\n",
    "p_other = norm(mu_other, 10).pdf(test_height)\n",
    "print(p_bball, p_other)\n",
    "\n",
    "if (p_bball > p_other): \n",
    "    print(str(test_height) + \" is more likely a professional basketball player\")\n",
    "else: \n",
    "    print(str(test_height) + \" is more likely NOT a professional basketball player\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "beta=stats.beta(a=10,b=2)\n",
    "beta_sample=beta.rvs(size=1000,random_state=133)\n",
    "t=np.linspace(0,1,100)\n",
    "plt.hist(beta_sample,density=True,label=\"Sample\")\n",
    "plt.plot(t,beta.pdf(t),label=\"PDF\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Beta Distribution\")\n",
    "plt.savefig(\"beta_hist_pdf.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Decision Trees \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **decision tree** represents a function that takes as input a vector of attribute values and return a **decision** - a single output value. The input and output values can be discrete or continuous. To make things simple we will focus initially on discrete attributes and a single binary output (true or false)(positive or negative). \n",
    "\n",
    "A decision tree makes a decision by performing a sequence of test. Each node in the tree corresponds to a test of the value of one of the input attributes $A_i$ and the branches from the node are labeled with the possible values of the attribute. Each leaf node in the tree specifies a value to be return by the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to think of a decision tree is as through propositional logic. The goal attribute is true if and only if the input attributes satisfy one of the paths leading to a leaf with value *true*: \n",
    "\n",
    "$$\n",
    "Goal <=> (Path_{1} \\lor Path_{2} \\lor \\dots)\n",
    "$$\n",
    "\n",
    "Each path is a conjuction of attribute-value tests required to follow the path. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inducing decision trees from examples\n",
    "\n",
    "\n",
    "An instance or example that can be used to \"train\" a decision tree consists of an $(\\bf{x},y)$ pair, where $x$ is a vector of values for the input attributes, and $y$ is a single output value. This is called the target (or goal) attribute and corresponds to whether $WillWait$ is $true$ or $false$. \n",
    "\n",
    "<img src=\"images/decision_tree_attributes.png\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "<img src=\"images/decision_tree.png\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "Ideally we would want the smallest possible tree that is consistent with the examples. However, this is an intractable problem as there are $2^{2^{n}}$ trees to consider. We can do a decent job using a greedy divide and conquer strategy. \n",
    "\n",
    "1. Choose a \"good\" attribute to split\n",
    "2. If all examples after a split are positive (or negative) then return the corresponding classification \n",
    "3. Create two subproblems based on the split\n",
    "4. Recursively repeat the process until there are no attributes left to split \n",
    "5. When there are are both positive and negative examples use plurality to make decision\n",
    "\n",
    "\n",
    "<img src=\"images/decision_tree_attribute_splits.png\" width=\"100%\"/>\n",
    "\n",
    "<img src=\"images/decision_tree_learning_algorithm.png\" width=\"50%\"/>\n",
    "\n",
    "<img src=\"images/induced_decision_tree.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing attribute tests\n",
    "\n",
    "We need a formal measure of \"fairly good\" and \"really useless\" to implement the $IMPORTANCE$ function. We will use the notation of information gain, which is defined in term of **entropy**, the fundamental quantity in information theory. \n",
    "\n",
    "**Entropy** of random variable: \n",
    "\n",
    "$$ \n",
    "H(V) = \\sum_{k} P(v_k) \\log_{2} \\frac{1}{P(v_k)} = - \\sum_{k} P(v_k) \\log_2P(v_k)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the entropy of a fair coin is 1 bit: \n",
    "$$\n",
    "H(Fair) = -(0.5 \\log_2 0.5 + 0.5 \\log_2 0.5) = 1\n",
    "$$\n",
    "\n",
    "If *Loaded* is a random coin with $0.99$ probability of being Head and $0.01$ probability of being tail we get: \n",
    "\n",
    "$$\n",
    "H(Loaded) = -(0.99 \\log_2 0.99 + 0.01 \\log_2 0.01) \\approx 0.08 bits\n",
    "$$\n",
    "\n",
    "Let's definte $B(q)$ as the entropy of a Boolean random variable that is true with probability $q$: \n",
    "$$\n",
    "B(q) = -\\left (q \\log_2 q + (1-q) \\log_2 (1 - q)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the training set contains $p$ positive examples and $n$ negative examples then the entropy of the target attribute on the whole set is: \n",
    "$$ \n",
    "H(Goal) = B\\left(\\frac{p}{p+n}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example the restaurant training set has $p=n=6$ so the corresponding entropy is $B(0.5) = 1$. A test on a single attribute(feature) might give us only part of this 1 bit. We can measure exactly how much by looking at the entropy remaining after the attribute test. \n",
    "Suppose that an attribute A with $d$ distinct values divides the training set $E$ into subset $E_1, \\dots E_d$. Each subset $E_k$ has $p_k$ positive examples and $n_k$ negative examples so if we go along that branch we need an additional $B(p_k/(p_k +n_k)$ bits of information to answer the question. A randomly chosen example from the training set has the kth value for the attribute with probability $(p_k + n_k)/(p + n)$, so the expected entropy remaining after testing attribute $A$ is \n",
    "$$ \n",
    "Remainder(A) = \\sum_{k=1}^{d} \\frac{(p_k + n_k)}{p+n} B\\left(\\frac{p_k}{p_k+n_k}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **information gain** from the attribute test on $A$ is expected reduction in entropy: \n",
    "$$ \n",
    "Gain(A) = B\\left(\\frac{p}{p+n}\\right) - Remainder(A) \n",
    "$$\n",
    "\n",
    "For example consider the attributes from our example we have: \n",
    "\n",
    "$$ \n",
    "Gain(Patrons) = 1 - \\left[\\frac{2}{12} B\\left(\\frac{0}{2}\\right) + \\frac{4}{12}B\\left(\\frac{4}{4}\\right)+ \\frac{6}{12}B\\left(\\frac{2}{6}\\right)\\right] \\approx 0.541 bits\n",
    "$$\n",
    "$$ \n",
    "Gain(Type) = 1 - \\left[\\frac{2}{12} B\\left(\\frac{1}{2}\\right) + \\frac{2}{12}B\\left(\\frac{1}{2}\\right)+ \\frac{4}{12}B\\left(\\frac{2}{4}\\right) + \\frac{4}{12}B\\left(\\frac{2}{4}\\right)\\right] = 0  bits\n",
    "$$\n",
    "\n",
    "\n",
    "### Additional topics \n",
    "\n",
    "* Overfitting\n",
    "* Decision tree pruning\n",
    "* Signficance test\n",
    "* Early stopping\n",
    "* Missing data\n",
    "* Multi-valued attributes\n",
    "* Continuous and integer-valued input attributes\n",
    "* Continuous-valued output attributes\n",
    "\n",
    "One **important property** of decision trees is that it is possible for a human to understand the reason for the output of the learning algorithm. This can be a **legal requirement** for financial decisions and is not the case in other learned representations such as neural networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data = np.array([['Yes', 'No', 'No', 'Yes', 'Some', '3D', 'No', 'Yes', 'French', '0_10', 'Yes'], \n",
    "                 ['Yes', 'No', 'No', 'Yes', 'Full', '1D', 'No', 'No', 'Thai', '30_60', 'No'],\n",
    "                 ['No' , 'Yes', 'No', 'No', 'Some', '1D', 'No', 'No',  'Burger', '0_10', 'Yes'],\n",
    "                 ['Yes' ,'No', 'Yes', 'Yes', 'Full', '1D', 'Yes', 'No', 'Thai', '10_30', 'Yes'],\n",
    "                 ['Yes', 'No', 'Yes' ,'No' ,'Full', '3D', 'No', 'Yes', 'French', '>60', 'No'],\n",
    "                 ['No',  'Yes', 'No', 'Yes', 'Some','2D', 'Yes', 'Yes', 'Italian', '0_10', 'Yes'], \n",
    "                 ['No', 'Yes' , 'No' , 'No' , 'None' ,'1D', 'Yes', 'No', 'Burger', '0_10', 'No'], \n",
    "                 ['No', 'No', 'No', 'Yes', 'Some', '2D', 'Yes', 'Yes', 'Thai', '0_10', 'Yes'], \n",
    "                 ['No', 'Yes','Yes', 'No', 'Full', '1D', 'Yes', 'No', 'Burger', '>60', 'No'],\n",
    "                 ['Yes', 'Yes', 'Yes', 'Yes', 'Full', '3D', 'No', 'Yes', 'Italian', '10_30', 'No'],\n",
    "                 ['No', 'No', 'No', 'No', 'None', '1D', 'No', 'No', 'Thai', '0_10', 'No'],\n",
    "                 ['Yes','Yes','Yes','Yes','Full', '1D', 'No', 'No', 'Burger','30_60', 'Yes']\n",
    "                ]\n",
    "               )\n",
    "\n",
    "feature_names = ['Alt', 'Bar', 'Fri', 'Hun', 'Pat', 'Price', 'Rain', 'Res', 'Type', 'Est'] \n",
    "target_name   = 'WillWait'\n",
    "df = pd.DataFrame(data, columns = feature_names + [target_name])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "\n",
    "categorical_features = df[feature_names]\n",
    "orig_target = df[target_name]\n",
    "print(categorical_features)\n",
    "print(orig_target)\n",
    "numerical_features = pd.DataFrame()\n",
    "# Encode categorical variables\n",
    "for f in feature_names: \n",
    "    numerical_features[f] = categorical_features[f].astype(\"category\").cat.codes\n",
    "target = orig_target.astype(\"category\").cat.codes\n",
    "print(numerical_features)\n",
    "print(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(numerical_features[feature_names].values, target.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtreeviz\n",
    "import matplotlib.font_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina' # Make visualizations look good\n",
    "#%config InlineBackend.figure_format = 'svg' \n",
    "%matplotlib inline\n",
    "\n",
    "viz_model = dtreeviz.model(clf,\n",
    "                           X_train=numerical_features[feature_names], y_train=target,\n",
    "                           feature_names=feature_names,\n",
    "                           target_name=target_name, class_names=[\"Yes\", \"No\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_model.view(scale=2.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating and choosing the best hypothesis \n",
    "\n",
    "\n",
    "When learning a machine learning model we want the model to perform \"well\" on \"future data\" not just the data that it was trained on. In order to be more precise we need to define what we mean by \"well\" and \"future data\". To do this we will make the **stationarity assumption**: that there is a probability distribution over the examples that does not change over time. Each example data point is random variable $E_j$ who observed value $e_j = (x_j, y_j)$ is sampled from that distribution and is independent of the previous examples: \n",
    "$$ \n",
    "{\\bf P}(E_j | E_{j-1}, E_{j-2}, \\dots) = {\\bf P}(E_j)\n",
    "$$, \n",
    "and each example has an identical prior probability distribution: \n",
    "$$\n",
    "{\\bf P}(E_j) = {\\bf P}(E_{j-1}) = {\\bf P}(E_{j-2}) = \\dots \n",
    "$$\n",
    "\n",
    "Examples that satisfy these assumptions are called independent and identically distributed or **i.i.d**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error rate \n",
    "\n",
    "The **error rate** of a hypothesis/model is the proportion of mistakes it makes - the proportion of \n",
    "times that the output of the model $h(x) \\neq y$ for an $(x,y$ example. The key observation is that because a hypothesis $h$ has a low error on the training set this deos not mean that it will generalize well. So in order to get an accurate idea of how well a particular model does we need to \n",
    "test it on examples it has not seen yet (i.e they have not been used for training). \n",
    "\n",
    "The simplest approach which is called **Hold-out cross-validation** is to randomly split the available labeled data into a training set from which the learning algorithm produces a hypothesis $h$ and a test set on which the accuracy of $h$ is evaluated. There are two challenges with this approach: not all data is used for training and it is unclear how much to use for training and how much to use for testing. \n",
    "\n",
    "A more sophisticated and pretty much standard approach in machine learning is what is called **k-fold cross-validation**. The labeled data is split into $k$ equal subsets (the folds). We then perform $k$ rounds of learning. In each round, one fold is held out as a test set and the remaining $k-1$ folds are used for training. \n",
    "\n",
    "**Peeking** occurs when adjustments are made on an algorithm based on how it is doing on the test set error rate. Information about the test set is leaked into the learning algorithm. To avoid this a common practice is to keep a test set completely separate and not evaluate it until all learning is complete. In order to otimize the model/learning algorithm instead a **validation** set can be used. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Linear Regression \n",
    "\n",
    "A very basic operation to consider is \"fitting\" a straight line. A univariate linear function with input $x$ and output $y$ has the form $y = w_1 x + w_o$ where $w_o$ and $w_1$ are real-valued coefficients to be learned. We use a vector $w$ instead of the more familiar $a$ and $b$ for reasons that will become apparent later. The vector $w$ is called the weights vector. So we have: \n",
    "\n",
    "$$ \n",
    "h_{\\bf w}(x) = w_1 x + w_0\n",
    "$$ \n",
    "\n",
    "Given a set of n training points on the plane, our task is to find the line that best fits these data points. This is called *linear regression*. We can use a squarred loss function $L_2$ summed over all the training examples: \n",
    "\n",
    "$$ \n",
    "Loss(h_{\\bf w}) = \\sum_{j=1}^{N} L_{2} (y_j, h_{\\bf w}(x_j))) = \\sum_{j=1}^{N}(y_j - h_{\\bf w}(x_j))^2 = \\sum_{j=1}^{N} (y_j - (w_{1} x_j+ + w_0))^2\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to find $w^{*} = \\text{argmin}_{\\bf w} Loss(h_{\\bf w})$ \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the partial derivatives to $0$ with respect to $w_0$ and $w_1$ we can find the unique \n",
    "solution for $w_1$ and $w_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many forms of learning involve adjusting weights to minimize a loss so we will look at linear regression from that perspective. One can think of the **weight space**, in linear regression a two dimensional space but in general a high dimensional space as the space defined by all possible settings of the weights. For linear regression there is a unique minimum and we can find it analytically. In most other cases in machine learning there is no close form solution and no single global minimum. \n",
    "\n",
    "Such problems can be addressed by a hill-climbing algorithm that follows the **gradient** of the function to be optimized. This is called **gradient descent**. The algorithm starts at any point in the weight space and then moves into a neighboring point that is downhill, repeating until we converge on the minimum possible loss. The weight update for gradient descent is: \n",
    "\n",
    "$$\n",
    "w_i \\leftarrow w_i - \\alpha \\frac{\\partial }{\\partial w_{i}} Loss({\\bf w})\n",
    "$$\n",
    "\n",
    "The parameter $\\alpha$, is called the **learning rate**. It can be a fixed constant, or it can decay over time as the learning process proceeds. For $N$ training examples, we want to minimize the sum of the individual losses for each example. The derivative of the sum is the sum of the derivatives so we have: \n",
    "\n",
    "$$\n",
    "w_0 \\leftarrow w_{0} + \\alpha \\sum_{j} (y_j - h_{\\bf w}(x_j))\n",
    "$$\n",
    "\n",
    "$$ \n",
    "w_1 \\rightarrow w_{1} + \\alpha \\sum_{j} (y_j - h_{\\bf w}(x_j)) \\times x_j \n",
    "$$ \n",
    "\n",
    "The updates constitute the **batch gradient descent** rule. An alternative is **stochastic gradient descent** where we consider only a random single training point at a time and taking an update step. \n",
    "\n",
    "It is straightforward to extend to **multi-variate linear regression**. \n",
    "\n",
    "$$\n",
    "h_{\\bf w}({\\bf x_j}) = w_{0} + w_{1}x_{j,1} + \\dots + w_n x_{j,n} = w_{0} + \\sum_{j}{w_{i}x_{j,i}}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common trick used to make the notation more compact is to invent a dummy input attribute $x_j,0$ which is always equal to $1$. The $h$ is simply the dot-product of the weights and the input vector (or equivalently, the matrix product of the transpose of the weights and the input vector): \n",
    "\n",
    "$$\n",
    "h_{w}({\\bf x_{j}}) = {\\bf w} \\cdot {\\bf x}_{j} = {\\bf w}^{T} {\\bf x}_{j} \n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best vector of weight, ${\\bf w}^{*}$, minimizes squarred-error loss over the examples: \n",
    "\n",
    "$$\n",
    "{\\bf w}{*} = \\text{argmin}_{\\bf w} \\sum_{j} L_{2}(y_j, {\\bf w} \\cdot {\\bf x_j})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear classification with a hard-threshold \n",
    "\n",
    "\n",
    "A **decision boundary** is a line (or surface) that separates two classes. A linear decision boundary is called a **linear separator** and data that admit such as a separator are called **linearly** separable. The classification hypothesis can be written as: \n",
    "\n",
    " \n",
    "$h_{\\bf w} ({\\bf x}) = 1$ if ${\\bf w} \\cdot {\\bf x} \\geq 0$  \n",
    "and $0$ otherwise. \n",
    "\n",
    "One can think of this process as passing the output of the linear function ${\\bf w} \\cdot {\\bf x}$ through a **threshold function**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Rule \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple weight update scheme that converges to a solution (linear separator) that classifies the data perfectly provided the data is linearly separable. For a single example $({\\bf x}, y)$ we have: \n",
    "\n",
    "$$ \n",
    "w_i \\leftarrow w_i + \\alpha (y - h_{\\bf w} ({\\bf x})) \\times x_i\n",
    "$$\n",
    "\n",
    "If the output is correct the weights are left unchanged. If $y$ (the ground truth) is $1$ and the output $h_{\\bf w}(\\bf x)$ is $0$ then $w_i$ is increased. If $y$ is $0$ and the output is $1$ then $w_i$ is decreased. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "In many cases, we are not just interested in a hard classification decision but would like to have a probability for each predicted class similarly to how we could get one from the Naive Bayes classifier. This is typically achieved by \"softening\" the threshold function and making it continuous and differentiable. \n",
    "\n",
    "The logistic function (also known as sigmoid) is defined as: \n",
    "$$\n",
    "Logistic(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "There is no closed formed for logistic regression but gradient descent works in a straightforward way because the logistic function is easy to differentiate. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminative Classification \n",
    "\n",
    "\n",
    "**Main Idea**: Instead of trying to model all the training data using\r\n",
    "probability density function just consider the linear decision\r\n",
    "boundary and focus on finding an optimal one. This directly\r\n",
    "solves the classification problem (at least for the binary case)\r\n",
    "rather than transforming it to the potentially more complex\r\n",
    "problem of fitting a distribution to a set of samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line equation (assume 2D first):\n",
    "$$ \n",
    "  w_2 x_2 + w_1 x_1 + b = 0\n",
    "$$\n",
    "\n",
    "* All points (x1 , x2 ) lying on the line make the\n",
    "equation true.\n",
    "*  The line separates the plane in two half-planes.\n",
    "*  The points (x1 , x2 ) in one half-plane give us an\n",
    "inequality with respect to 0, which has the same direction\n",
    "for each of the points in the half-plane.\n",
    "* Fact4: The points (x1 , x2 ) in the other half-plane give us\n",
    "the reverse inequality with respect to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear decision boundary can be generalized to a high-dimensional hyperplane \n",
    "\n",
    "$$\n",
    "g({\\bf x}) = {\\bf w}^T {\\bf x} + w0 = 0,\n",
    "$$\n",
    "where $w = [w_1,w_2,\\dots,w_l]^T$ is the weight vector and $w_0$ is the\n",
    "threshold.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron \n",
    "\n",
    "\n",
    "<img src=\"images/perceptron.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron was invented by Frank Rosenblatt when he was 32 years old and was embodied in hardware. He was interested in neurobiology and learning and later would do a\n",
    "lot of work with rats (including injecting material from trained rats brains to untrained ones) and died in 1971 at the age of 43 in a boating accident.\n",
    "\n",
    "<img src=\"images/rosenblatt.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron was essentially the first computer that could\n",
    "learn new skill sby trial and error, using a type of simplified\n",
    "neural network informed by findings in neurobiology involving\n",
    "the human thought process.\n",
    "    \n",
    "**Quote:**\n",
    "The embryo of an electronic computer that the Navy expects\n",
    "will be able to walk, talk, see, write, reproduce itself and be\n",
    "conscious of its existence - 1958, New York Times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceptrons was a book written by Marvin Minsky and\n",
    "Seymour Papert in 1969 that argued that emphasis should be\n",
    "placed on so called symbolic systems (things like first-order\n",
    "logic and knowledge representation) rather than biologically\n",
    "inspired low-level systems like neural networks. Marvin Misnky\n",
    "was extremely influential at the time and effectively reduced\n",
    "funding for research in neural works to nothing in the 1970s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/minksy_papert_1971.png\" width=\"100%\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of the basic perceptron\n",
    "\n",
    "* Informed by neuro-biology\n",
    "* Initial optimism replaced by scepticism. The field of ANNs was killed for ten years in the 70s.\n",
    "* Well suited for online processing - easy to implement\n",
    "* Only works for linearly separable datasets\n",
    "* Prone to overfitting - no consideration of margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Regression refers to the problem of predicting continuous\n",
    "values whereas in classification we predict discrete categorical\n",
    "values. Ordinal classification is a special case that is somewhat\n",
    "inbetween where there are discrete values but there is an\n",
    "implied ordering of them (for example short, average, tall).\n",
    "Ordinal classification can be treated as a classification problem\n",
    "in which case the ordering is ignored or as a regression\n",
    "problem in which case threshold values between the classes\n",
    "need to be established."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron Networks\n",
    "\n",
    "Also known as Artificial Neural Networks (ANNs). Resurgence\n",
    "in the 1980s when the backpropagation training algorithm\n",
    "became popular. Backpropagation requires that the activation\n",
    "function is differentiable (replacing the step function used in\n",
    "the basic Perceptron, for example, with a sigmoid function).\n",
    "Allows arbitrary modeling of input to output supporting\n",
    "naturally classification as well as regression and multilabel\n",
    "classification. Fell out of fashion around 2000 with the rise of\n",
    "the support vector machines but resurfaced with the \n",
    "deep learning revolution of 2010. \n",
    "\n",
    "<img src=\"images/mlp.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characteristics of ANNs\n",
    "\n",
    "* Slow convergence - training\n",
    "* Prone to overfitting due to the large number of\n",
    "parameters\n",
    "* Can solve complex problems in addition to classification\n",
    "* Unclear how to find the optimal architercture for the\n",
    "hidden layer(s)\n",
    "*  Easy to parallelize - deep learning resurgence has been\n",
    "enabled among other things by GPU processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "\n",
    "When a problem is linearly separable there are several \n",
    "hyperplanes that satisfy perfect separation. If we could choos \r\n",
    "among them is there any reason to prefer one over another ?\r\n",
    "Hyperplane that leaves more ‚Äúroom‚Äù on either side should be\r\n",
    "chosen so that data from both classes can ‚Äúmove‚Äù more fr ely\r\n",
    "with less risk of causing an error. The formal term for this\r\n",
    "‚Äúroom‚Äù is called the margin and our goal is to have th  same\r\n",
    "distance to the nearest poi$\\omega_t$s in $\\omega_1$and œâ2 . So now ins ead of\r\n",
    "simply searching for a hyperplane that perfectly separ tes the\r\n",
    "two classes we also have the additional require ent of a\r\n",
    "maximum margin. This can be cast as non-linear ( uadratic)\r\n",
    "optimization problem subject to a set of linear constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vladimir Vapnik not affected by the ‚ÄúAI Winter‚Äù of the 1970s was inspired by the perceptron and created a mathematical \n",
    "theory of statistical learning. In the 1990s he moved to th United States \r\n",
    "where while in Bel Labs where  he developed Support Vector Machine.\n",
    "\n",
    "<img src=\"images/separating_hyperplane_svm.png\" width=\"100%\"/>\n",
    "\n",
    "\n",
    "<img src=\"images/vapnik.png\" width=\"30%\"/>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Characteristics of SVMs\n",
    "\n",
    "* Effective in high dimensional spaces\n",
    "* Uses only a subset (the support vectors) of training points\n",
    "* All operations involve inner products (Kernel trick)\n",
    "* Do not directly provide probability estimates but can be extended to do so\n",
    "* Require normalization of the training data (min/max)\n",
    "* Binary classifier needs to be extended for multi-class using one-vs-all or all-pairs.\n",
    "* Prediction can be extremely fast\n",
    "* Generalization is backed by elegant theory\n",
    "* Hard to implement optimization but a lot of good implementations exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other approaches \n",
    "\n",
    "* Non-parametric - K-Nearest Neighbor \n",
    "* Ensemble methods - (AdaBoost, Random Forests) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet \n",
    "\n",
    "Fei Fei Li \n",
    "\n",
    "[The Worlds I See: Curiosity, Exploration, and Discovery at the Dawn of AI](https://www.amazon.ca/Worlds-See-Curiosity-Exploration-Discovery-ebook/dp/B0BPQSLVL6) \n",
    "\n",
    "<img src=\"images/imagenet.png\" width=\"100%\"/>\n",
    "\n",
    "<img src=\"images/feifeili.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were many attempts to train and use ANNs with more\n",
    "than one hidden layer but due to various practical problems\n",
    "(including long training times and lack of large amounts of\n",
    "data) they did not become succsessful until around 2009-2010.\n",
    "Advances in GPUs enabled faster training and availability of\n",
    "larger amounts of training data resulted in a resurgence of\n",
    "interest in Neural Network architectures and they were shown\n",
    "to provide superior performance than existing state-of-the-art\n",
    "algorithms for a variety of tasks such as image classification in\n",
    "computer vision and automatic speech recognition. The last few years \n",
    "there has been  enormous interest by companies (Google\n",
    "Brain, Facebook AI) with a lot of excellent software being\n",
    "developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
